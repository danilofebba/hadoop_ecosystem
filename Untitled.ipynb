{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e483b9-916b-456a-8c15-8480da38a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snakebite.client import Client\n",
    "# the below line create client connection to the HDFS NameNode\n",
    "client = Client('192.168.43.2', 9000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "744f9287-a558-442d-ae64-4b82e9bddf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_type': 'f', 'permission': 420, 'path': '/warehouse/dados.csv', 'length': 76, 'owner': 'dr.who', 'group': 'supergroup', 'block_replication': 1, 'modification_time': 1623908111875, 'access_time': 1623908111235, 'blocksize': 134217728}\n"
     ]
    }
   ],
   "source": [
    "# the loop iterate in root directory to list all the content \n",
    "for x in client.ls(['/warehouse']):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c1eb13-36ab-437e-9f17-5b1ef705b5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c428969-fefb-4cbc-8505-f575d6f5f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a87ee89-fb4c-4468-9d53-28d4cd94cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkSession = SparkSession.builder.appName(\"example-pyspark-read-and-write\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b480a4-ec81-49ec-8569-b02b26ebf4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sparkSession.createDataFrame([{\"id\":1,\"name\":\"danilo\"},{\"id\":2,\"name\":\"daniel\"},{\"id\":3,\"name\":\"luana\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0643342-22f8-405f-9a24-10c984e84edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet(\"hdfs://hadoop:9000/warehouse/{0}\".format(uuid.uuid4()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf80b78-bb6b-44e9-89b2-973acbffc057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sparkSession.read.csv('hdfs://192.168.43.2:9000/warehouse/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ca4721-f876-420a-ab2e-2058481fc973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------------------+\n",
      "|_c0|   _c1|                _c2|\n",
      "+---+------+-------------------+\n",
      "| id|  name|         created_at|\n",
      "|  1|Danilo|2021-06-10 22:47:18|\n",
      "|  2| Luana|2021-06-10 22:50:00|\n",
      "+---+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3aaee-1116-402d-a45f-805b2194d8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
